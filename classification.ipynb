{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tag.perceptron import AveragedPerceptron\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.random.seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/dpapp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/dpapp/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/dpapp/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>prefix</th>\n",
       "      <th>features</th>\n",
       "      <th>hours</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>DS</td>\n",
       "      <td>Linear RegressionCorrelationRegression Analysi...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Statistical Analysis</td>\n",
       "      <td>DS</td>\n",
       "      <td>Statistical AnalysisDescriptive StatisticsInfe...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logarithms</td>\n",
       "      <td>DS</td>\n",
       "      <td>LogarithmsExponential FunctionsLogarithmic Fun...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arithmetics</td>\n",
       "      <td>DS</td>\n",
       "      <td>ArithmeticOperationsAdditionSubtractionMultipl...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Euclidean distance</td>\n",
       "      <td>DS</td>\n",
       "      <td>Euclidean DistanceDistance FormulaPythagorean ...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name prefix  \\\n",
       "0     Linear Regression     DS   \n",
       "1  Statistical Analysis     DS   \n",
       "2            Logarithms     DS   \n",
       "3           Arithmetics     DS   \n",
       "4    Euclidean distance     DS   \n",
       "\n",
       "                                            features  hours  cluster  \n",
       "0  Linear RegressionCorrelationRegression Analysi...   0.75        1  \n",
       "1  Statistical AnalysisDescriptive StatisticsInfe...   1.50        1  \n",
       "2  LogarithmsExponential FunctionsLogarithmic Fun...   2.00        1  \n",
       "3  ArithmeticOperationsAdditionSubtractionMultipl...   0.50        1  \n",
       "4  Euclidean DistanceDistance FormulaPythagorean ...   2.25        1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus = pd.read_csv(r\"input/603_num.tsv\", sep='\\t')\n",
    "\n",
    "Corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus['text'].dropna(inplace=True)\n",
    "\n",
    "Corpus['features'] = [entry.lower() for entry in Corpus['features']]\n",
    "\n",
    "Corpus['tokens']= [word_tokenize(entry) for entry in Corpus['features']]\n",
    "\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "for index, entry in enumerate(Corpus['tokens']):\n",
    "    final_words = []\n",
    "    word_lemmatized = WordNetLemmatizer()\n",
    "    for word, tag in pos_tag(entry):\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_final = word_lemmatized.lemmatize(word, tag_map[tag[0]])\n",
    "            final_words.append(word_final)\n",
    "    Corpus.loc[index, 'text_final'] = str(final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>prefix</th>\n",
       "      <th>features</th>\n",
       "      <th>hours</th>\n",
       "      <th>cluster</th>\n",
       "      <th>tokens</th>\n",
       "      <th>text_final</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>DS</td>\n",
       "      <td>linear regressioncorrelationregression analysi...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>[linear, regressioncorrelationregression, anal...</td>\n",
       "      <td>['linear', 'regressioncorrelationregression', ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Statistical Analysis</td>\n",
       "      <td>DS</td>\n",
       "      <td>statistical analysisdescriptive statisticsinfe...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>[statistical, analysisdescriptive, statisticsi...</td>\n",
       "      <td>['statistical', 'analysisdescriptive', 'statis...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logarithms</td>\n",
       "      <td>DS</td>\n",
       "      <td>logarithmsexponential functionslogarithmic fun...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[logarithmsexponential, functionslogarithmic, ...</td>\n",
       "      <td>['logarithmsexponential', 'functionslogarithmi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arithmetics</td>\n",
       "      <td>DS</td>\n",
       "      <td>arithmeticoperationsadditionsubtractionmultipl...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>[arithmeticoperationsadditionsubtractionmultip...</td>\n",
       "      <td>['arithmeticoperationsadditionsubtractionmulti...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Euclidean distance</td>\n",
       "      <td>DS</td>\n",
       "      <td>euclidean distancedistance formulapythagorean ...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1</td>\n",
       "      <td>[euclidean, distancedistance, formulapythagore...</td>\n",
       "      <td>['euclidean', 'distancedistance', 'formulapyth...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name prefix  \\\n",
       "0     Linear Regression     DS   \n",
       "1  Statistical Analysis     DS   \n",
       "2            Logarithms     DS   \n",
       "3           Arithmetics     DS   \n",
       "4    Euclidean distance     DS   \n",
       "\n",
       "                                            features  hours  cluster  \\\n",
       "0  linear regressioncorrelationregression analysi...   0.75        1   \n",
       "1  statistical analysisdescriptive statisticsinfe...   1.50        1   \n",
       "2  logarithmsexponential functionslogarithmic fun...   2.00        1   \n",
       "3  arithmeticoperationsadditionsubtractionmultipl...   0.50        1   \n",
       "4  euclidean distancedistance formulapythagorean ...   2.25        1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [linear, regressioncorrelationregression, anal...   \n",
       "1  [statistical, analysisdescriptive, statisticsi...   \n",
       "2  [logarithmsexponential, functionslogarithmic, ...   \n",
       "3  [arithmeticoperationsadditionsubtractionmultip...   \n",
       "4  [euclidean, distancedistance, formulapythagore...   \n",
       "\n",
       "                                          text_final label  \n",
       "0  ['linear', 'regressioncorrelationregression', ...        \n",
       "1  ['statistical', 'analysisdescriptive', 'statis...        \n",
       "2  ['logarithmsexponential', 'functionslogarithmi...        \n",
       "3  ['arithmeticoperationsadditionsubtractionmulti...        \n",
       "4  ['euclidean', 'distancedistance', 'formulapyth...        "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus['label'] = ''\n",
    "Corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text_final'], Corpus['label'], test_size=0.3)\n",
    "\n",
    "Encoder = LabelEncoder()\n",
    "\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "\n",
    "Test_Y = Encoder.fit_transform(Test_Y)\n",
    "\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "Tfidf_vect.fit(Corpus['text_final'])\n",
    "\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "\n",
    "Test_Y = Encoder.fit_transform(Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(Corpus['text_final'])\n",
    "\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'linear': 432, 'regressioncorrelationregression': 700, 'analysisleast': 50, 'squarescoefficient': 801, 'determinationregression': 212, 'lineindependent': 434, 'variabledependent': 910, 'variablepredictionoutliersresidualsconfidence': 911, 'intervalhypothesis': 403, 'testinganovastatistical': 848, 'inferencemultiple': 386, 'regressionmodel': 701, 'selectionregularizationridge': 752, 'regressionthis': 703, 'module': 522, 'design': 209, 'introduce': 404, 'student': 817, 'regression': 699, 'powerful': 609, 'statistical': 807, 'technique': 838, 'use': 901, 'model': 500, 'relationship': 707, 'two': 886, 'variable': 909, 'interactive': 398, 'lesson': 426, 'activity': 10, 'learn': 420, 'build': 109, 'interpret': 400, 'result': 723, 'make': 450, 'prediction': 613, 'draw': 239, 'conclusion': 159, 'data': 192, 'cover': 182, 'assumption': 87, 'limitation': 430, 'well': 930, 'validate': 906, 'improve': 380, 'also': 40, 'different': 222, 'type': 887, 'include': 381, 'simple': 770, 'multiple': 527, 'apply': 73, 'problem': 623, 'end': 256, 'strong': 815, 'understanding': 895, 'able': 1, 'wide': 932, 'range': 686, 'field': 315, 'business': 110, 'social': 779, 'science': 741, 'natural': 530, 'regressionstatistical': 702, 'techniquemodeling': 839, 'relationshipsbuilding': 708, 'modelsinterpreting': 514, 'resultsmaking': 724, 'analysisdescriptive': 47, 'statisticsinferential': 808, 'statisticsprobabilitydistributionshypothesis': 809, 'testingconfidence': 849, 'intervalcentral': 402, 'limit': 429, 'theoremsampling': 854, 'methodsstatistical': 491, 'inferenceregression': 387, 'testcorrelationexperimental': 846, 'designnonparametric': 210, 'statisticstime': 810, 'series': 756, 'analysismultivariate': 53, 'analysisbig': 44, 'analyticsmachine': 62, 'learningthis': 423, 'teach': 837, 'fundamental': 342, 'analysis': 42, 'collection': 142, 'organization': 573, 'case': 116, 'study': 818, 'informed': 390, 'decision': 198, 'meaningful': 476, 'basic': 94, 'concept': 157, 'measure': 477, 'central': 117, 'tendency': 841, 'variance': 915, 'standard': 802, 'deviation': 217, 'advanced': 16, 'topic': 868, 'hypothesis': 369, 'testing': 847, 'comprehensive': 155, 'analysisdata': 46, 'collectiondata': 143, 'organizationdata': 574, 'analysismeasures': 52, 'tendencyhypothesis': 842, 'testingregression': 850, 'analysisvariancestandard': 59, 'deviationbusinesssciencesocial': 218, 'logarithmsexponential': 441, 'functionslogarithmic': 338, 'functionsproperties': 340, 'logarithmsnatural': 443, 'logarithmlogarithmic': 439, 'equationslogarithmic': 270, 'differentiationexponential': 224, 'growthexponential': 361, 'decaychange': 195, 'base': 93, 'formulainverse': 326, 'functionstrigonometryhyperbolic': 341, 'functionscalculusderivativesintegralscomplex': 337, 'numbersapplications': 545, 'logarithmsmathematical': 442, 'modelingbig': 507, 'notationthis': 539, 'logarithms': 440, 'important': 379, 'mathematical': 463, 'many': 458, 'engineering': 257, 'finance': 317, 'property': 676, 'rule': 734, 'logarithm': 437, 'solve': 789, 'exponential': 304, 'equation': 265, 'logarithmic': 438, 'function': 334, 'application': 68, 'population': 604, 'growth': 360, 'radioactive': 684, 'decay': 194, 'solid': 781, 'scientific': 744, 'functionspopulation': 339, 'growthradioactive': 362, 'arithmeticoperationsadditionsubtractionmultiplicationdivisionfractionsdecimalsintegersreal': 79, 'numbersabsolute': 544, 'valueexponentsrootsorder': 908, 'operationsscientific': 562, 'notationpercentagesratiosproportionslinear': 538, 'equationsthis': 271, 'arithmetic': 78, 'whole': 931, 'number': 543, 'operation': 558, 'fraction': 333, 'decimal': 197, 'percentage': 590, 'develop': 215, 'reasoning': 691, 'skill': 777, 'strategy': 814, 'mental': 481, 'math': 462, 'estimation': 278, 'help': 364, 'become': 95, 'efficient': 252, 'effective': 246, 'learner': 421, 'confidence': 163, 'need': 531, 'tackle': 834, 'operationsfractionsdecimalspercentagesmental': 561, 'euclidean': 280, 'distancedistance': 235, 'formulapythagorean': 327, 'theoremcartesian': 852, 'coordinateseuclidean': 176, 'spacedistance': 795, 'metricsmetric': 493, 'spacesnormsinner': 796, 'productsorthogonalityunit': 657, 'vectorsvectorsvector': 920, 'spacesvector': 797, 'additionscalar': 13, 'multiplicationdot': 528, 'productcross': 654, 'productmatricesmatrix': 656, 'operationseigenvaluesin': 560, 'distance': 234, 'mathematics': 465, 'computer': 156, 'point': 602, 'space': 794, 'notion': 541, 'angle': 66, 'explore': 303, 'calculate': 112, 'dimension': 227, 'pythagorean': 680, 'theorem': 851, 'extend': 305, 'high': 367, 'look': 446, 'practical': 610, 'machine': 449, 'learning': 422, 'clear': 139, 'distancemathematicscomputer': 236, 'sciencepythagorean': 743, 'theoremdata': 853, 'analysismachine': 51, 'programmingmodelingcomputer': 670, 'implementationsensitivity': 376, 'analysisuncertaintygraphical': 58, 'methodcomputer': 485, 'modelspost': 516, 'analysisparametersscenariosnew': 56, 'variablesnew': 914, 'constraintsmanual': 169, 'sensitivity': 754, 'analysisautomatic': 43, 'analysisobjective': 54, 'functiondecision': 335, 'variablesconstraintsoptimizationfeasibilitymathematical': 913, 'modelsin': 512, 'return': 725, 'modeling': 506, 'process': 646, 'present': 615, 'implement': 374, 'post': 606, 'method': 482, 'uncertainty': 891, 'may': 473, 'occur': 552, 'parameter': 583, 'potential': 607, 'scenario': 739, 'add': 11, 'new': 535, 'constraint': 167, 'graphical': 356, 'conduct': 161, 'manually': 457, 'solution': 782, 'automatically': 89, 'programmingcomputer': 662, 'solutionssolverexcelampllindogamsalgorithmsensitivity': 788, 'analysisshadow': 57, 'pricesdual': 618, 'probleminterior': 632, 'methodbranch': 483, 'bound': 106, 'methodnetwork': 487, 'simplex': 771, 'methodinteger': 486, 'programmingnonlinear': 671, 'programmingheuristicsmetaheuristicsartificial': 668, 'intelligencein': 397, 'lp': 448, 'formulation': 329, 'complex': 151, 'manner': 455, 'specifically': 799, 'discuss': 232, 'one': 556, 'popular': 603, 'algorithm': 21, 'phase': 595, 'initialization': 391, 'iteration': 412, 'termination': 844, 'output': 577, 'generate': 347, 'software': 780, 'tool': 867, 'available': 91, 'greatly': 359, 'simplify': 772, 'reduce': 696, 'risk': 730, 'error': 276, 'provide': 677, 'experience': 299, 'give': 350, 'good': 354, 'programming': 661, 'methodcomputational': 484, 'solutionsinitializationiterationterminationsoftware': 786, 'shortestpathexampleshortest': 766, 'pathshortshortest': 588, 'pathwelcome': 589, 'short': 765, 'path': 586, 'example': 289, 'find': 319, 'graph': 355, 'search': 746, 'dijkstra': 226, 'key': 415, 'compare': 149, 'efficiency': 250, 'approach': 74, 'thorough': 858, 'searchdijkstra': 747, 'algorithmpathfinding': 27, 'algorithmspath': 34, 'efficiencyshortest': 251, 'maximalflowexampleproblemgraph': 470, 'theorywelcome': 857, 'maximal': 469, 'flow': 322, 'theory': 855, 'network': 532, 'detail': 211, 'examine': 288, 'maximize': 472, 'conduit': 162, 'understand': 894, 'underlying': 893, 'principle': 619, 'challenging': 131, 'reward': 728, 'comenetwork': 145, 'algorithmmaximal': 26, 'problemconduitsgraph': 626, 'principlesmodule': 620, 'challenge': 130, 'travellingaialgorithmexampleproblemtravelling': 880, 'salesman': 736, 'problemin': 631, 'travel': 879, 'classic': 138, 'list': 435, 'city': 137, 'pair': 581, 'must': 529, 'possible': 605, 'tour': 871, 'visit': 922, 'exactly': 286, 'way': 927, 'increase': 382, 'ability': 0, 'come': 144, 'withclassic': 933, 'sciencecity': 742, 'tourdistance': 872, 'matrixalgorithm': 467, 'solutionsshortest': 787, 'pathoptimal': 587, 'route': 732, 'session': 760, 'goal': 353, 'development': 216, 'deterministic': 214, 'stochastic': 813, 'video': 921, 'research': 718, 'general': 346, 'definition': 201, 'define': 200, 'optimization': 567, 'objective': 549, 'subject': 819, 'certain': 118, 'history': 368, 'common': 146, 'program': 660, 'identify': 371, 'component': 153, 'operational': 559, 'transportation': 877, 'inventory': 406, 'queue': 682, 'unique': 896, 'benefit': 98, 'various': 917, 'importance': 378, 'fix': 321, 'cost': 178, 'optimize': 570, 'package': 580, 'change': 132, 'mistake': 496, 'evaluate': 281, 'effectiveness': 248, 'logic': 444, 'artificial': 81, 'intelligence': 396, 'neural': 534, 'tree': 882, 'expert': 300, 'system': 825, 'expand': 296, 'discussion': 233, 'purpose': 678, 'determine': 213, 'unit': 897, 'product': 653, 'volume': 923, 'sell': 753, 'produce': 652, 'equate': 264, 'total': 870, 'revenue': 726, 'witht': 936, 'costthe': 180, 'equal': 263, 'call': 113, 'profit': 659, 'loss': 447, 'additionally': 12, 'demonstrate': 207, 'proficiency': 658, 'inference': 385, 'statistic': 806, 'numerical': 546, 'analyze': 63, 'trend': 883, 'represent': 714, 'appropriate': 75, 'chart': 135, 'probability': 622, 'bias': 100, 'predictive': 614, 'variables': 912, 'feasible': 313, 'optimal': 563, 'explain': 301, 'isidentify': 411, 'constraintsdescribe': 168, 'step': 812, 'processanalyze': 647, 'modelconstruct': 503, 'notationutilize': 540, 'solver': 790, 'modelsinterpret': 513, 'solversutilize': 791, 'effect': 245, 'modeluse': 519, 'excel': 290, 'create': 186, 'modelutilize': 520, 'modelthis': 518, 'serve': 757, 'introduction': 405, 'go': 352, 'region': 698, 'often': 555, 'management': 453, 'scientist': 745, 'efficiently': 253, 'allocate': 36, 'resourceswe': 720, 'try': 884, 'minimize': 495, 'functionmany': 336, 'time': 861, 'costin': 179, 'walk': 926, 'formulate': 328, 'involve': 408, 'specific': 798, 'feasiblesolutions': 314, 'foundation': 332, 'maximization': 471, 'minimization': 494, 'graphically': 357, 'knowledge': 417, 'infeasible': 384, 'obtain': 551, 'focus': 323, 'construct': 170, 'representation': 715, 'previous': 616, 'purposedemonstrate': 679, 'manual': 456, 'tableauutilize': 833, 'perform': 591, 'automatic': 88, 'analysisidentify': 48, 'shadow': 764, 'price': 617, 'bind': 102, 'modelscompute': 510, 'allowable': 39, 'value': 907, 'modelapply': 501, 'modelsdiscuss': 511, 'impact': 373, 'modelformulate': 505, 'variety': 916, 'problemsanalyze': 633, 'allow': 38, 'context': 172, 'start': 803, 'tableau': 832, 'observe': 550, 'move': 525, 'finally': 316, 'degeneracysensitivity': 203, 'today': 864, 'dive': 238, 'deep': 199, 'commonly': 147, 'behind': 97, 'work': 937, 'analysisinfeasibility': 49, 'describe': 208, 'implication': 377, 'furniture': 343, 'economic': 243, 'interpretation': 401, 'company': 148, 'entire': 260, 'set': 761, 'dual': 240, 'bland': 105, 'role': 731, 'programmingexplain': 666, 'algorithmanalyze': 22, 'advantage': 17, 'disadvantage': 229, 'algorithmapply': 23, 'problemsdifferentiate': 638, 'problemsrecognize': 642, 'require': 716, 'execute': 293, 'algorithmutilize': 35, 'illustrate': 372, 'algorithmidentify': 24, 'best': 99, 'reach': 688, 'problemexplain': 629, 'algorithmin': 25, 'overview': 579, 'world': 939, 'decide': 196, 'right': 729, 'slack': 778, 'contrast': 173, 'deal': 193, 'get': 349, 'familiar': 309, 'mix': 498, 'integer': 394, 'binary': 101, 'three': 859, 'correctly': 177, 'input': 392, 'recognize': 692, 'show': 768, 'chain': 119, 'resource': 719, 'allocation': 37, 'production': 655, 'differentiate': 223, 'modeldemonstrate': 504, 'affect': 18, 'solutionanalyze': 783, 'modelcompute': 502, 'coefficient': 141, 'side': 769, 'yield': 941, 'solutionsdemonstrate': 784, 'modelsapply': 509, 'assess': 82, 'course': 181, 'actionexplain': 9, 'modelsanalyze': 508, 'order': 571, 'remove': 712, 'report': 713, 'parametric': 584, 'perturbation': 594, 'degeneracy': 202, 'unboundedness': 889, 'term': 843, 'address': 14, 'know': 416, 'evaluation': 282, 'review': 727, 'pert': 593, 'manage': 452, 'project': 675, 'logical': 445, 'diagram': 220, 'critical': 188, 'expect': 297, 'relevant': 709, 'methodology': 488, 'cpm': 184, 'duration': 241, 'identification': 370, 'sequence': 755, 'construction': 171, 'probabilistic': 621, 'distribution': 237, 'estimate': 277, 'expected': 298, 'complete': 150, 'within': 934, 'uncertain': 890, 'event': 283, 'budget': 108, 'mitigate': 497, 'associate': 85, 'response': 721, 'plan': 599, 'information': 389, 'optimistic': 566, 'crashing': 185, 'leveling': 428, 'without': 935, 'action': 8, 'accurately': 7, 'timeline': 862, 'area': 76, 'saving': 738, 'balance': 92, 'schedule': 740, 'applicationsanalyze': 69, 'algorithms': 28, 'relate': 704, 'programmingsolve': 673, 'dynamic': 242, 'programminguse': 674, 'problemsidentify': 639, 'heuristic': 365, 'problemanalyze': 624, 'factor': 308, 'problemdevelop': 627, 'programmingevaluate': 665, 'solutionsdevelop': 785, 'implementation': 375, 'algorithmsexplain': 33, 'concise': 158, 'exploration': 302, 'programmingfeasible': 667, 'real': 690, 'integral': 395, 'discrete': 231, 'ready': 689, 'unlock': 899, 'power': 608, 'feasibility': 312, 'branch': 107, 'cut': 191, 'plane': 600, 'restrict': 722, 'take': 835, 'mixed': 499, 'among': 41, 'others': 575, 'andoptimization': 64, 'applied': 72, 'problemsunderstand': 643, 'problemsdemonstrate': 636, 'problemapply': 625, 'element': 254, 'problemevaluate': 628, 'particular': 585, 'problemidentify': 630, 'tradeoff': 873, 'coveringcompare': 183, 'methodssynthesize': 492, 'novel': 542, 'interger': 399, 'us': 900, 'wrap': 940, 'setoptimization': 762, 'componentsutilize': 154, 'university': 898, 'selection': 751, 'applicationscomprehend': 70, 'problemscalculate': 634, 'programmingidentify': 669, 'algorithmsdevelop': 32, 'problemsutilize': 645, 'problemsdesign': 637, 'test': 845, 'performance': 592, 'algorithmscompare': 29, 'select': 750, 'onecreate': 557, 'summarize': 822, 'recommendation': 693, 'next': 536, 'see': 749, 'lecture': 424, 'gain': 345, 'moduleobjective': 523, 'admission': 15, 'insight': 393, 'problemsknapsack': 641, 'tsp': 885, 'facility': 307, 'location': 436, 'assignment': 83, 'planning': 601, 'characteristic': 133, 'situation': 775, 'irregular': 409, 'arise': 77, 'unbounded': 888, 'irregularity': 410, 'transshipment': 878, 'global': 351, 'environmental': 262, 'current': 189, 'grasp': 358, 'let': 427, 'individual': 383, 'mastery': 461, 'related': 705, 'job': 413, 'workload': 938, 'used': 902, 'difference': 221, 'traffic': 874, 'task': 836, 'routing': 733, 'utilization': 904, 'optimizationnetwork': 569, 'modelsnetworkgraph': 515, 'theoryflow': 856, 'networknodes': 533, 'quality': 681, 'analysisconstrainedoptimizationconstraints': 45, 'associated': 86, 'demand': 206, 'supply': 823, 'place': 597, 'placement': 598, 'guide': 363, 'choose': 136, 'effectively': 247, 'nonlinear': 537, 'linearization': 433, 'complexity': 152, 'optimizationglobal': 568, 'unconstrained': 892, 'equationsidentify': 269, 'equationsdesign': 267, 'equationapply': 266, 'accuracyanalyze': 5, 'convergence': 175, 'rate': 687, 'bisection': 104, 'secant': 748, 'methodscompare': 489, 'methodsimplement': 490, 'equationsdevelop': 268, 'numericallyutilize': 548, 'accuracytest': 6, 'equationswelcome': 273, 'numerically': 547, 'analytically': 61, 'differentnumerical': 225, 'equationsunconstrainedoptimizationiterative': 272, 'employ': 255, 'mathematically': 464, 'form': 325, 'spreadsheet': 800, 'conflict': 165, 'ethical': 279, 'confidently': 164, 'togoal': 865, 'programmingoptimization': 672, 'criterion': 187, 'refine': 697, 'assist': 84, 'utilize': 905, 'familiarize': 310, 'throughout': 860, 'oflinear': 553, 'useful': 903, 'environment': 261, 'conflicting': 166, 'requirement': 717, 'analytic': 60, 'hierarchy': 366, 'ahp': 19, 'multicriteria': 526, 'mcda': 474, 'anp': 67, 'making': 451, 'satisfy': 737, 'running': 735, 'memory': 480, 'exist': 295, 'aid': 20, 'shouldpath': 767, 'edge': 244, 'weight': 928, 'direct': 228, 'topological': 869, 'sorting': 792, 'medical': 478, 'successful': 820, 'optimally': 564, 'record': 694, 'paragraph': 582, 'welcome': 929, 'diagnostics': 219, 'treatment': 881, 'code': 140, 'techniquescompare': 840, 'algorithmsconstruct': 30, 'manipulate': 454, 'modelsutilize': 517, 'problemsinterpret': 640, 'programmingdesign': 663, 'problemsconstruct': 635, 'efficacy': 249, 'algorithmsdemonstrate': 31, 'programmingdevelop': 664, 'matter': 468, 'queuing': 683, 'arrival': 80, 'service': 759, 'customer': 190, 'wait': 924, 'discipline': 230, 'andwaiting': 65, 'line': 431, 'length': 425, 'systemsanalyze': 830, 'systemdevelop': 829, 'systemdescribe': 828, 'characteristicsimplement': 134, 'languageanalyze': 419, 'simulationdesign': 774, 'control': 174, 'timesdevelop': 863, 'systemuse': 831, 'systemapply': 827, 'ensure': 258, 'delivery': 205, 'meet': 479, 'investigate': 407, 'monitor': 524, 'modify': 521, 'deliver': 204, 'excellent': 291, 'excite': 292, 'journeyqueuing': 414, 'capacity': 114, 'behavior': 96, 'server': 758, 'finite': 320, 'varying': 919, 'size': 776, 'availability': 90, 'suitable': 821, 'vary': 918, 'overall': 578, 'waiting': 925, 'optimise': 565, 'setup': 763, 'formultiple': 330, 'exercise': 294, 'genetic': 348, 'state': 804, 'transition': 876, 'markov': 459, 'predict': 612, 'accuracy': 4, 'reliability': 710, 'language': 418, 'processing': 650, 'structure': 816, 'forward': 331, 'ofmarkov': 554, 'random': 685, 'processescalculate': 648, 'ergodic': 275, 'processunderstand': 651, 'relation': 706, 'stationary': 805, 'conditionsbe': 160, 'matrix': 466, 'processesdevelop': 649, 'applicationsdemonstrate': 71, 'simulation': 773, 'chainsapply': 126, 'everyone': 285, 'fascinating': 311, 'chainsconvergence': 127, 'chainsexplain': 128, 'ordinary': 572, 'absorb': 2, 'chainsanalyze': 125, 'chaincalculate': 120, 'chaininterpret': 123, 'absorption': 3, 'chaindevelop': 121, 'problemsuse': 644, 'eventidentify': 284, 'systemanalyze': 826, 'chainformulate': 122, 'equilibrium': 274, 'chainwelcome': 129, 'preceding': 611, 'zero': 942, 'mean': 475, 'enters': 259, 'remain': 711, 'forever': 324, 'chainsabsorbing': 124, 'markovstationary': 460, 'recurrent': 695, 'transient': 875, 'future': 344, 'external': 306, 'influence': 388, 'source': 793, 'synthesize': 824, 'phenomenon': 596, 'financial': 318, 'biological': 103, 'careful': 115, 'examination': 287, 'outcome': 576, 'byapplications': 111, 'analysisof': 55, 'tomarkov': 866, 'steady': 811}\n"
     ]
    }
   ],
   "source": [
    "print(Tfidf_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  100.0\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1 class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Classifier - Algorithm - SVM\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# fit the training dataset on the classifier\u001b[39;00m\n\u001b[1;32m      3\u001b[0m SVM \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mSVC(C\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m, kernel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpoly\u001b[39m\u001b[39m'\u001b[39m, degree\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, max_iter\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m SVM\u001b[39m.\u001b[39;49mfit(Train_X_Tfidf,Train_Y)\n\u001b[1;32m      5\u001b[0m \u001b[39m# predict the labels on validation dataset\u001b[39;00m\n\u001b[1;32m      6\u001b[0m predictions_SVM \u001b[39m=\u001b[39m SVM\u001b[39m.\u001b[39mpredict(Test_X_Tfidf)\n",
      "File \u001b[0;32m~/Projects/emse-mms/emse-mms/venv/lib/python3.10/site-packages/sklearn/svm/_base.py:201\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m    193\u001b[0m         X,\n\u001b[1;32m    194\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    199\u001b[0m     )\n\u001b[0;32m--> 201\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_targets(y)\n\u001b[1;32m    203\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[1;32m    204\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[1;32m    205\u001b[0m )\n\u001b[1;32m    206\u001b[0m solver_type \u001b[39m=\u001b[39m LIBSVM_IMPL\u001b[39m.\u001b[39mindex(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl)\n",
      "File \u001b[0;32m~/Projects/emse-mms/emse-mms/venv/lib/python3.10/site-packages/sklearn/svm/_base.py:749\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight_ \u001b[39m=\u001b[39m compute_class_weight(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight, classes\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m, y\u001b[39m=\u001b[39my_)\n\u001b[1;32m    748\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mcls\u001b[39m) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 749\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    750\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe number of classes has to be greater than one; got \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m class\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    751\u001b[0m         \u001b[39m%\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    752\u001b[0m     )\n\u001b[1;32m    754\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\n\u001b[1;32m    756\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
     ]
    }
   ],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='poly', degree=3, gamma='auto', max_iter=100)\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
